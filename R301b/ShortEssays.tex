\documentclass[DIV=14,titlepage=false]{scrreprt}
\input{preamble.tex}
\setuptoc{toc}{leveldown}
\usepackage{enumitem}

\begin{document}
\pagenumbering{gobble}
\vspace{-10pt}

\chapter*{Short Essay Solutions}

\section*{Discrete Choice Models}

\textbf{\textit{[2021-R301b]\\
 Evaluate the statement that The feasibility of the control function approach depends upon whether the analyst can isolate the error term in the reduced form equation so that it can be conditioned on in the structural equation.}}

\vspace{5pt}

\textbf{\textit{[2019- IIB Paper 10] \\
 Following either a change in the size of the choice set or a change in one of the attributes associated with a particular alternative, the mixed logit model circumvents the most restrictive feature of the conditional logit model, namely proportional substitution between discrete alternatives.}}

\vspace{5pt}

\textbf{\textit{[2019,2018,2017,2016 - IIB Paper 10] \\ 
Relative to the linear probability model, there are fewer advantages to the threshold binary response model when the matrix of regressors is sparse or when there are endogenous binary regressors.}}

\vspace{5pt}

\textbf{\textit{[2018,2017,2016 - IIB Paper 10] \\ 
The relative advantages of the random coe?cient (mixed) logit model over logit are potentially compromised when the mixing distribution is assumed to be multivariate normal.}}

\section*{Panel Data}

\textbf{\textit{[2022,2023 - R301b] \\
For the correlated random effects estimator (cre), the equivalence of $\hat \beta_{CRE} = \hat \beta_{FE}$ implies an interesting interpretation of the fixed effects (fe) estimator: it controls for the average level Â¯xi when measuring the partial effects of xit on yit}}

\vspace{5pt}

\textbf{\textit{[2022-R301b] \\
For a linear panel data model with a lagged dependent variable, the strict exogeneity assumption fails to hold, such that a conventional fixed effects estimator is inconsistent for fixed T. Discuss.}}

\vspace{5pt}

\textbf{\textit{[2022-IIB Paper 10] \\
The random effects estimator is a weighted version of the between and the within (fixed effect) estimator. The random effects estimator is a Generalised Least Squares version of the pooled ols estimator.}}

\vspace{5pt}

\textbf{\textit{[2019,2018,2017,2016 - IIB Paper 10] \\
 If in a linear fixed effects (fe) static panel data model, time series variation around regressors xit is limited, the evaluation of the fe and competing estimators using mean square error may be appropriate.}}

\section*{Bayesian}

\textbf{\textit{[2023 - R301b] \\
In a Bayesian panel data model the classical fixed versus random effects dichotomy is not relevant.}}

\vspace{5pt}

\textbf{\textit{[2019 - R301b] \\
 Evaluate the statement that From a Bayesian point of view there is no distinction between fixed and random effects panel data models, only between hierarchical and non-hierarchical models.}}

\section*{Machine Learning}

\textbf{\textit{[2023 - R301b] \\
A regression tree is honest if, for each training observation i, it only uses a given observation to estimate the within-leaf treatment effect or to decide where to place the splits, but not both.}}

\vspace{5pt}

\textbf{\textit{[2023 - R301b] \\
The genesis of random forests can be linked to a departure from the specification of a linear conditional expectation function, addressing a dimensionality problem when the number of regressors is large relative to sample size, and the need to reduce the variance of single regression trees.}}

\vspace{5pt}

\textbf{\textit{[2022-R301b] \\
 How does the standard regression tree algorithm determine which attributes to put at the root of the tree?}}

\vspace{5pt}

\textbf{\textit{[2022-R301b] \\
 Although a random forest represents a solution to the problem of instability of single regression trees, the solution generates an inability to deal with non i.i.d processes. Discuss.}}

\vspace{5pt}

\textbf{\textit{[2021,2019-R301b] \\
 In what sense does a random forest represent a solution to the problem of instability of single regression trees? In what sense is interpretability of single trees compromised by this method?}}

\vspace{5pt}

\textbf{\textit{[2021-R301b, 2021-IIB Paper 10] \\
 In machine learning a dataset is often divided into training and testing data, denoted by $S_{tr}$ and $S_{te}$ respectively. Explain the basis for this and why further sample splitting on $S_{tr}$ may also be appropriate.}}

\vspace{5pt}

\textbf{\textit{[2019-R301b, 2021,2019,2018-IIB Paper 10] \\
 Evaluate the statement that Certain variable transformations, that would be redundant for a standard linear regression model and create collinearities, can be valuable in penalized linear models or other machine-learning predictors.}}

\vspace{5pt}

\textbf{\textit{[2022,2021 - IIB Paper 10] \\
 In representing a conditional mean function $\E[y|x] = g(x)$, where the column dimension of x may exceed the number of observations and $g(x)$ is learnt from the data, a regression tree trades off bias for variance.}}

\vspace{5pt}

\textbf{\textit{[2022,2021- IIB Paper 10] \\ 
The conditional expectation function implied by the application of the recursive binary splitting algorithm to training data $S_{tr}$ is piecewise nonlinear.}}

\vspace{5pt}

\textbf{\textit{[2019,2018 - IIB Paper 10] \\
 The exploration of heterogeneous treatment effects is a prediction problem and is better addressed using machine learning methods.}}

\end{document}
